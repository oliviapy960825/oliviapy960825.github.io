subv <- c(1,2,3,4,5,6,7,8,9,10)
g2 <- induced.subgraph(graph=simplified_g,vids=subv)
plot(g2)
g3 <- add_vertices(g2,11)
plot(g3)
add.edges(g3,c(11,1))
add.edges(g3,c(11,3))
plot(g3)
atri <- count_triangles(g3)
plot(g3, vertex.label=atri)
plot(g3, vertex.label=atri)
plot(g3, vertex.label=atri)
plot(g3, vertex.label=atri)
list <- as_adj_list(g3)
print(list)
edge_list=as_adj_edge_list(g3)
print(edge_list)
closeness.cent <- closeness(g, mode="all")
closeness.cent
sort(closeness.cent, decreasing = TRUE)
dia<-diameter(g)
dia
get_diameter(g)
sort(closeness.cent, decreasing = FALSE)
plot(simplified_g)
plot(g2)
is_simple(g)
is.simple(g)
fileName<- "~/Desktop/CSCI6444/Project 1/email-EU/email-EU.edges"
con <- file(fileName,open="r")
lines<-readLines(con)
lines
data<-read.table(textConnection(lines))
library(tidyverse)
library(igraph)
data %>%
rename(
FromNode = V1,
ToNode = V2
)
g <- graph_from_data_frame(data, directed=TRUE)
print(g, e=TRUE, v=TRUE)
adjmatrix = as_adjacency_matrix(g)
adjmatrix
simplified_g<-simplify(g)
subv <- c(1,2,3,4,5,6,7,8,9,10)
g2 <- induced.subgraph(graph=simplified_g,vids=subv)
plot(g2)
View(g)
set.seed(42)
cl <- walktrap.community(g, steps = 5)
cl$degree <- (degree(g)[cl$names])
cl$cluster <- unname(ave(cl$degree, cl$membership, FUN=function(x)names(x)[which.max(x)]))
V(g)$name <- cl$cluster
E(g)$weight <- 1
V(g)$weight <- 1
gcon <- contract.vertices(g, cl$membership, vertex.attr.comb = list(weight = "sum", name = function(x)x[1], "ignore"))
gcon <- simplify(gcon, edge.attr.comb = list(weight = "sum", function(x)length(x)))
gcon <- simplify(gcon, edge.attr.comb = list(weight = "sum", function(x) length(x)))
gcon <- simplify(gcon, edge.attr.comb = list(weight = "sum", function(x)length(x)))
gcc <- induced.subgraph(gcon, V(gcon)$weight > 20)
V(gcc)$degree <- unname(degree(gcc))
set.seed(42)
par(mar = rep(0.1, 4))
g.layout <- layout.kamada.kawai(gcc)
plot.igraph(gcc, edge.arrow.size = 0.1, layout = g.layout, vertex.size = 0.5 * (V(gcc)$degree))
power_centrality(g2, nodes= V(g2), loops=FALSE, exponent=1, rescale = False, tol = 1e-07, sparse = TRUE)
power_centrality(g2, nodes= V(g2), loops=FALSE, exponent=1, rescale = FALSE, tol = 1e-07, sparse = TRUE)
power_centr=power_centrality(g2, nodes= V(g2), loops=FALSE, exponent=1, rescale = FALSE, tol = 1e-07, sparse = TRUE)
sort(power_centr, decreasing = FALSE)
page_rank(simplified_g)
sg1 <- decompose.graph(simplified_g,mode="weak")
sg1
sg=induced.subgraph(g2, which(V(g2)$weight>0.5))
plot(sg,edge.label=round(E(sg)$weight,3))
plot(sg,edge.label=round(E(sg)$weight))
plot(sg,edge.label=round(E(sg)$weight), 3)
V(sg)$weight=rnorm(vcount(sg))
E(sg)$weight=rnorm(ecount(sg))
plot(sg,edge.label=round(E(sg)$weight), 3)
plot(sg)
page_rank(g2)
wc=walktrap.community(simplified_g)
plot(wc,simplified_g,vertex.size=.5, layout=layout.fruchterman.reingold)
wc=walktrap.community(g2)
plot(wc,g2,vertex.size=.5, layout=layout.fruchterman.reingold)v
plot(wc,g2,vertex.size=.5, layout=layout.fruchterman.reingold)
neighverts <- unique(unlist(sapply(sg1,FUN=function(s){if(any(V(s)$name %in% subv)) V(s)$name else NULL})))
neighverts
fileName<- "~/Desktop/CSCI6444/Project 1/email-EU/email-EU.edges"
con <- file(fileName,open="r")
lines<-readLines(con)
lines
data<-read.table(textConnection(lines))
data<-read.table(textConnection(lines))
library(igraph)
g <- graph_from_data_frame(data, directed=TRUE)
print(g, e=TRUE, v=TRUE)
set.seed(42)
cl <- walktrap.community(g, steps = 5)
cl$degree <- (degree(g)[cl$names])
cl$cluster <- unname(ave(cl$degree, cl$membership, FUN=function(x)names(x)[which.max(x)]))
V(g)$name <- cl$cluster
E(g)$weight <- 1
V(g)$weight <- 1
gcon <- contract.vertices(g, cl$membership, vertex.attr.comb = list(weight = "sum", name = function(x)x[1], "ignore"))
gcon <- simplify(gcon, edge.attr.comb = list(weight = "sum", function(x)length(x)))
install.packages("igraph")
gcon <- simplify(gcon, edge.attr.comb = list(weight = "sum", function(x)length(x)))
gcon <- contract.vertices(g, cl$membership, vertex.attr.comb = list(weight = "sum", name = function(x)x[1], "ignore"))
cl$cluster <- unname(ave(cl$degree, cl$membership, FUN=function(x)names(x)[which.max(x)]))
V(g)$name <- cl$cluster
install.packages("igraph")
library(igraph)
cl$degree <- (degree(g)[cl$names])
cl$cluster <- unname(ave(cl$degree, cl$membership, FUN=function(x)names(x)[which.max(x)]))
V(g)$name <- cl$cluster
E(g)$weight <- 1
V(g)$weight <- 1
V(g)$weight <- 1
gcon <- contract.vertices(g, cl$membership, vertex.attr.comb = list(weight = "sum", name = function(x)x[1], "ignore"))
gcon <- simplify(gcon, edge.attr.comb = list(weight = "sum", function(x)length(x)))
gcc <- induced.subgraph(gcon, V(gcon)$weight > 20)
V(gcc)$degree <- unname(degree(gcc))
set.seed(42)
par(mar = rep(0.1, 4))
g.layout <- layout.kamada.kawai(gcc)
plot.igraph(gcc, edge.arrow.size = 0.1, layout = g.layout, vertex.size = 0.5 * (V(gcc)$degree))
fileName<- "~/Desktop/CSCI6444/Project 1/email-EU/email-EU.edges"
con <- file(fileName,open="r")
lines<-readLines(con)
lines
data<-read.table(textConnection(lines))
library(tidyverse)
data %>%
rename(
FromNode = V1,
ToNode = V2
)
g <- graph_from_data_frame(data, directed=TRUE)
adjmatrix = as_adjacency_matrix(g)
simplified_g<-simplify(g)
subv <- c(1,2,3,4,5,6,7,8,9,10)
g2 <- induced.subgraph(graph=simplified_g,vids=subv)
plot(g2)
set.seed(42)
cl <- walktrap.community(g, steps = 5)
cl$degree <- (degree(g)[cl$names])
cl$cluster <- unname(ave(cl$degree, cl$membership, FUN=function(x)names(x)[which.max(x)]))
V(g)$name <- cl$cluster
E(g)$weight <- 1
V(g)$weight <- 1
gcon <- contract.vertices(g, cl$membership, vertex.attr.comb = list(weight = "sum", name = function(x)x[1], "ignore"))
gcon <- simplify(gcon, edge.attr.comb = list(weight = "sum", function(x) length(x)))
library(igraph)
gcon <- simplify(gcon, edge.attr.comb = list(weight = "sum", function(x) length(x)))
fileName<- "~/Desktop/CSCI6444/Project 1/email-EU/email-EU.edges"
con <- file(fileName,open="r")
lines<-readLines(con)
data<-read.table(textConnection(lines))
library(igraph)
install.packages(“igraph”)
install.packages("igraph")
install.packages("igraph")
library(igraph)
g <- graph_from_data_frame(data, directed=TRUE)
adjmatrix = as_adjacency_matrix(g)
simplified_g<-simplify(g)
subv <- c(1,2,3,4,5,6,7,8,9,10)
g2 <- induced.subgraph(graph=simplified_g,vids=subv)
plot(g2)
cl <- walktrap.community(g, steps = 5)
cl$degree <- (degree(g)[cl$names])
cl$cluster <- unname(ave(cl$degree, cl$membership, FUN=function(x)names(x)[which.max(x)]))
V(g)$name <- cl$cluster
E(g)$weight <- 1
V(g)$weight <- 1
gcon <- contract.vertices(g, cl$membership, vertex.attr.comb = list(weight = "sum", name = function(x)x[1], "ignore"))
gcon <- simplify(gcon, edge.attr.comb = list(weight = "sum", function(x) length(x)))
gcc <- induced.subgraph(gcon, V(gcon)$weight > 20)
V(gcc)$degree <- unname(degree(gcc))
set.seed(42)
par(mar = rep(0.1, 4))
g.layout <- layout.kamada.kawai(gcc)
plot.igraph(gcc, edge.arrow.size = 0.1, layout = g.layout, vertex.size = 0.5 * (V(gcc)$degree))
g3 <- add_vertices(g2,11)
plot(g3)
add.edges(g3,c(11,1))
add.edges(g3,c(11,3))
plot(g3)
atri <- count_triangles(g3)
plot(g3, vertex.label=atri)
list <- as_adj_list(g3)
print(list)
edge_list=as_adj_edge_list(g3)
print(edge_list)
diameter(g, directed = TRUE, unconnected = TRUE, weights = NULL)
radius(g, mode = 'all')
betweenness(g)
is_directed(g)
edge_density(g, loops=TRUE)
## Write an R function to search through the documents to find a specific word or phrase. Print the document number, line number, and word index in the sentence
setwd("~/Desktop/CSCI6444/Project 2/part_c")
getwd()
SAT<-VCorpus(DirSource(".",ignore.case=TRUE, mode="text"))
library(quanteda)
library(corpustools)
library(readtext)
library(wordcloud)
library(tm)
library(textreuse)
library(wordnet)
library(zipfR)
library(ggplot2)
library(stringi)
library(reshape2)
library(RWeka)
SAT<-VCorpus(DirSource(".",ignore.case=TRUE, mode="text"))
SAT
inspect(SAT)
length(SAT)
print(SAT[[1]]$content)
## Write an R function to search through the documents to find a specific word or phrase. Print the document number, line number, and word index in the sentence
setwd("~/Desktop/CSCI6444/Project 2/part_c")
getwd()
SAT<-VCorpus(DirSource(".",ignore.case=TRUE, mode="text"))
print(SAT[[1]]$content)
## Write an R function to search through the documents to find a specific word or phrase. Print the document number, line number, and word index in the sentence
install.packages("striprt")
library(striprtf)
print(strip_rtf(SAT[[1]]$content))
text<-strip_rtf(SAT[[1]]$content)
words <- tokenize_words(text)
words
match('distribution',words)
text
sentences<- gsub("[\r\n]", "", text)
sentences
sentences <-unlist( stringr::str_match_all(sentences, "[^\\s][^\\.\\!\\?]+[\\.\\!\\?]{1}") )
sentences
print(length(sentences))
sentences <-unlist( stringr::str_match_all(text, "[^\\s][^\\.\\!\\?]+[\\.\\!\\?]{1}") )
sentences
sentences[[1]]
sentence<-sentences[[1]]
sentence
#print(length(sentences))
words <- tokenize_words(sentence)
words
match('distribution',words)
print(is.na(match('distribution',words))==FALSE)
print(is.na(match('distribution',words))==TRUE)
filepath="~/Desktop/CSCI6444/Project 2/part_c"
find_words(filepath=filepath,"absolutely")
find_words<- function(filepath, word){
setwd(filepath)
SAT<-VCorpus(DirSource(".",ignore.case=TRUE, mode="text"))
for(index in 1:length(SAT)){
text<-strip_rtf(SAT[[index]]$content)
sentences <-unlist( stringr::str_match_all(text, "[^\\s][^\\.\\!\\?]+[\\.\\!\\?]{1}") )
for(sen_index in 1: length(sentences)){
sentence<-sentences[[sen_index]]
words <- tokenize_words(sentence)
word_index<-match(word,words)
if(is.na(word_index)==FALSE){
print("the document number is: "+index)
print("the line number is: "+sen_index)
print("the word index number is: "+word_index)
}
}
}
}
filepath="~/Desktop/CSCI6444/Project 2/part_c"
find_words(filepath=filepath,"absolutely")
find_words<- function(filepath, word){
setwd(filepath)
SAT<-VCorpus(DirSource(".",ignore.case=TRUE, mode="text"))
for(index in 1:length(SAT)){
text<-strip_rtf(SAT[[index]]$content)
sentences <-unlist( stringr::str_match_all(text, "[^\\s][^\\.\\!\\?]+[\\.\\!\\?]{1}") )
for(sen_index in 1: length(sentences)){
sentence<-sentences[[sen_index]]
words <- tokenize_words(sentence)
word_index<-match(word,words)
if(is.na(word_index)==FALSE){
sprintf("the document number is: "+index)
sprintf("the line number is: "+sen_index)
sprintf("the word index number is: "+word_index)
}
}
}
}
filepath="~/Desktop/CSCI6444/Project 2/part_c"
find_words(filepath=filepath,"absolutely")
find_words<- function(filepath, word){
setwd(filepath)
SAT<-VCorpus(DirSource(".",ignore.case=TRUE, mode="text"))
for(index in 1:length(SAT)){
text<-strip_rtf(SAT[[index]]$content)
sentences <-unlist( stringr::str_match_all(text, "[^\\s][^\\.\\!\\?]+[\\.\\!\\?]{1}") )
for(sen_index in 1: length(sentences)){
sentence<-sentences[[sen_index]]
words <- tokenize_words(sentence)
word_index<-match(word,words)
if(is.na(word_index)==FALSE){
print("the document number is: "+as.numeric(index))
print("the line number is: "+as.numeric(sen_index))
print("the word index number is: "+as.numeric(word_index))
}
}
}
}
filepath="~/Desktop/CSCI6444/Project 2/part_c"
find_words(filepath=filepath,"absolutely")
find_words<- function(filepath, word){
setwd(filepath)
SAT<-VCorpus(DirSource(".",ignore.case=TRUE, mode="text"))
for(index in 1:length(SAT)){
text<-strip_rtf(SAT[[index]]$content)
sentences <-unlist( stringr::str_match_all(text, "[^\\s][^\\.\\!\\?]+[\\.\\!\\?]{1}") )
for(sen_index in 1: length(sentences)){
sentence<-sentences[[sen_index]]
words <- tokenize_words(sentence)
word_index<-match(word,words)
if(is.na(word_index)==FALSE){
print("the document number is: ", index)
print("the line number is: ", sen_index)
print("the word index number is: ", word_index)
}
}
}
}
filepath="~/Desktop/CSCI6444/Project 2/part_c"
find_words(filepath=filepath,"absolutely")
print(words)
find_words<- function(filepath, word){
setwd(filepath)
SAT<-VCorpus(DirSource(".",ignore.case=TRUE, mode="text"))
for(index in 1:length(SAT)){
text<-strip_rtf(SAT[[index]]$content)
sentences <-unlist( stringr::str_match_all(text, "[^\\s][^\\.\\!\\?]+[\\.\\!\\?]{1}") )
for(sen_index in 1: length(sentences)){
sentence<-sentences[[sen_index]]
words <- tokenize_words(sentence)
print(words)
word_index<-match(word,words)
if(is.na(word_index)==FALSE){
print("the document number is: ", index)
print("the line number is: ", sen_index)
print("the word index number is: ", word_index)
}
}
}
}
filepath="~/Desktop/CSCI6444/Project 2/part_c"
find_words(filepath=filepath,"absolutely")
find_words(filepath=filepath,"warranty")
find_words<- function(filepath, word){
setwd(filepath)
SAT<-VCorpus(DirSource(".",ignore.case=TRUE, mode="text"))
for(index in 1:length(SAT)){
text<-strip_rtf(SAT[[index]]$content)
sentences <-unlist( stringr::str_match_all(text, "[^\\s][^\\.\\!\\?]+[\\.\\!\\?]{1}") )
for(sen_index in 1: length(sentences)){
sentence<-sentences[[sen_index]]
words <- tokenize_words(sentence)
print(words)
word_index<-match(word,words)
if(is.na(word_index)==FALSE){
print("the document number is: ", index)
print("the line number is: ", sen_index)
print("the word index number is: ", word_index)
}
}
}
}
filepath="~/Desktop/CSCI6444/Project 2/part_c"
find_words(filepath=filepath,"warranty")
find_words<- function(filepath, word){
setwd(filepath)
SAT<-VCorpus(DirSource(".",ignore.case=TRUE, mode="text"))
index=1
while(index <= length(SAT)){
text<-strip_rtf(SAT[[index]]$content)
sentences <-unlist( stringr::str_match_all(text, "[^\\s][^\\.\\!\\?]+[\\.\\!\\?]{1}") )
sen_index=1
while(sen_index <= length(sentences)){
sentence<-sentences[[sen_index]]
words <- tokenize_words(sentence)
print(words)
word_index<-match(word,words)
if(is.na(word_index)==FALSE){
print("the document number is: ", index)
print("the line number is: ", sen_index)
print("the word index number is: ", word_index)
}
sen_index=sen_index+1
}
index=index+1
}
}
filepath="~/Desktop/CSCI6444/Project 2/part_c"
find_words(filepath=filepath,"warranty")
#print(words)
word_index<-match(word,words)
find_words<- function(filepath, word){
setwd(filepath)
SAT<-VCorpus(DirSource(".",ignore.case=TRUE, mode="text"))
index=1
while(index <= length(SAT)){
text<-strip_rtf(SAT[[index]]$content)
sentences <-unlist( stringr::str_match_all(text, "[^\\s][^\\.\\!\\?]+[\\.\\!\\?]{1}") )
sen_index=1
while(sen_index <= length(sentences)){
sentence<-sentences[[sen_index]]
words <- tokenize_words(sentence)
#print(words)
word_index<-match(word,words)
if(is.na(word_index)==FALSE){
print("the document number is: ", index)
print("the line number is: ", sen_index)
print("the word index number is: ", word_index)
}
sen_index=sen_index+1
}
index=index+1
}
}
filepath="~/Desktop/CSCI6444/Project 2/part_c"
find_words(filepath=filepath,"warranty")
find_words<- function(filepath, word){
setwd(filepath)
SAT<-VCorpus(DirSource(".",ignore.case=TRUE, mode="text"))
index=1
while(index <= length(SAT)){
text<-strip_rtf(SAT[[index]]$content)
sentences <-unlist( stringr::str_match_all(text, "[^\\s][^\\.\\!\\?]+[\\.\\!\\?]{1}") )
sen_index=1
while(sen_index <= length(sentences)){
sentence<-sentences[[sen_index]]
words <- tokenize_words(sentence)
#print(words)
word_index<-match(word,words)
if(!is.na(word_index)){
print("the document number is: ", index)
print("the line number is: ", sen_index)
print("the word index number is: ", word_index)
}
sen_index=sen_index+1
}
index=index+1
}
}
filepath="~/Desktop/CSCI6444/Project 2/part_c"
find_words(filepath=filepath,"warranty")
find_words<- function(filepath, word){
setwd(filepath)
SAT<-VCorpus(DirSource(".",ignore.case=TRUE, mode="text"))
index=1
while(index <= length(SAT)){
text<-strip_rtf(SAT[[index]]$content)
sentences <-unlist( stringr::str_match_all(text, "[^\\s][^\\.\\!\\?]+[\\.\\!\\?]{1}") )
sen_index=1
while(sen_index <= length(sentences)){
sentence<-sentences[[sen_index]]
words <- tokenize_words(sentence)
#print(words)
word_index<-match(word,words)
if(!is.na(word_index)){
print("the document number is: ")
print(index)
print("the line number is: ", sen_index)
print("the word index number is: ", word_index)
}
sen_index=sen_index+1
}
index=index+1
}
}
filepath="~/Desktop/CSCI6444/Project 2/part_c"
find_words(filepath=filepath,"warranty")
find_words<- function(filepath, word){
setwd(filepath)
SAT<-VCorpus(DirSource(".",ignore.case=TRUE, mode="text"))
index=1
while(index <= length(SAT)){
text<-strip_rtf(SAT[[index]]$content)
sentences <-unlist( stringr::str_match_all(text, "[^\\s][^\\.\\!\\?]+[\\.\\!\\?]{1}") )
sen_index=1
while(sen_index <= length(sentences)){
sentence<-sentences[[sen_index]]
words <- tokenize_words(sentence)
#print(words)
word_index<-match(word,words)
if(!is.na(word_index)){
print("the document number is: ")
print(index)
print("the line number is: ")
print(sen_index)
print("the word index number is: ")
print(word_index)
}
sen_index=sen_index+1
}
index=index+1
}
}
filepath="~/Desktop/CSCI6444/Project 2/part_c"
find_words(filepath=filepath,"warranty")
find_words(filepath=filepath,"absolutely")
find_words(filepath=filepath,"publications")
find_words(filepath = filepath, "lunatics")
